{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\source\\Pythonrepos\\Learning\\Learning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Імпортуємо потрібні бібліоттеки\n",
    "import tensorflow as tf #Для конвертації tensorflow датасету у звичайний датасет\n",
    "import tensorflow_datasets as tfds #Звідси ми візьмемо потрібний датасет\n",
    "import spacy #Для безпосереднь навчання\n",
    "import pandas as pd #Для роботи з датафреймами\n",
    "from spacy.tokens import DocBin #Для серіалізаціЇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'AMD #39;s new dual-core Opteron chip is desi...</td>\n",
       "      <td>3</td>\n",
       "      <td>b'AMD Debuts Dual-Core Opteron Processor'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Reuters - Major League Baseball\\\\Monday anno...</td>\n",
       "      <td>1</td>\n",
       "      <td>b\"Wood's Suspension Upheld (Reuters)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'President Bush #39;s  quot;revenue-neutral q...</td>\n",
       "      <td>2</td>\n",
       "      <td>b'Bush reform may have blue states seeing red'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Britain will run out of leading scientists u...</td>\n",
       "      <td>3</td>\n",
       "      <td>b\"'Halt science decline in schools'\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'London, England (Sports Network) - England m...</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Gerrard leaves practice'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label  \\\n",
       "0  b'AMD #39;s new dual-core Opteron chip is desi...      3   \n",
       "1  b'Reuters - Major League Baseball\\\\Monday anno...      1   \n",
       "2  b'President Bush #39;s  quot;revenue-neutral q...      2   \n",
       "3  b'Britain will run out of leading scientists u...      3   \n",
       "4  b'London, England (Sports Network) - England m...      1   \n",
       "\n",
       "                                            title  \n",
       "0       b'AMD Debuts Dual-Core Opteron Processor'  \n",
       "1           b\"Wood's Suspension Upheld (Reuters)\"  \n",
       "2  b'Bush reform may have blue states seeing red'  \n",
       "3            b\"'Halt science decline in schools'\"  \n",
       "4                      b'Gerrard leaves practice'  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = tfds.load('ag_news_subset', split='train', shuffle_files=True) #Завантажуємо потрібний датасет tensorflow.org/datasets/catalog/ag_news_subset\n",
    "assert isinstance(ds_train, tf.data.Dataset) #Вказуємо що завантажений об'єкт має формат tensorflow датасету\n",
    "df_train = tfds.as_dataframe(ds_train) #Конвертуємо його в датафрейм, з яким зможе працювати spacy\n",
    "ds_test = tfds.load('ag_news_subset', split='test', shuffle_files=True) #Повторюємо попередні кроки для другої частини даних\n",
    "assert isinstance(ds_test, tf.data.Dataset)\n",
    "df_test = tfds.as_dataframe(ds_test)\n",
    "df_train.head() #Виведемо частину даних, щоб перевірити коректну роботу програми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20416 Test: 4083 Valid: 1021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #Для розділення датафрейму на два випадкових датафрейма\n",
    "\n",
    "allDF = pd.concat((df_train, df_test), ignore_index=True) #Зв'язуємо два датафрейма в один\n",
    "allDF = allDF.sample(frac=0.2).reset_index(drop=True) #Беремо частину даних щоб пришвидшити роботу\n",
    "\n",
    "trainDF, testDF = train_test_split(allDF, test_size = 0.2) #Розділяємо датафрейм на два, один буде для тренування (80%) інший для тестування (20%)\n",
    "testDF, validDF = train_test_split(testDF, test_size = 0.2) #Розділяємо тренувальний датафрейм на два, один залишится для тестування (16%)\n",
    "#Інший буде для валідації (4%)\n",
    "\n",
    "print(\"Train:\",len(trainDF), \"Test:\", len(testDF),\"Valid:\", len(validDF)) #Виведемо кількість даних в кожному датафреймі\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Як можна побачити коли ми виводили перші 5 рядків датафрейму у секції 2, текстова інформація зберігається у вигляді байтів.\n",
    "#Тож після кожного оновлення датасету потрібно буде конвертувати строку байтів у формат, з яким може працювати spacy\n",
    "def from_byte_to_string(text): #Конвертує строку байтів у звичайну строку\n",
    "    answer = text.decode(\"utf-8\")\n",
    "    return answer\n",
    "\n",
    "def from_int_to_string(number): #Конвертує число у строку\n",
    "    answer = str(number)\n",
    "    return answer\n",
    "\n",
    "def first_process(df): #Конвертує усі байтові строки і числа у датасеті у звичайні строки\n",
    "    df.description = df.description.apply(from_byte_to_string)\n",
    "    df.label = df.label.apply(from_int_to_string)\n",
    "    \n",
    "def preprocess(df, embed): #Попередня обробка даних, \n",
    "    data = tuple(zip(df.description.tolist(), df.label.tolist())) #Об'єднуємо датафрейми у кортежі\n",
    "    nlp = spacy.load(embed) #Завантажуємо trained pipeline\n",
    "    docs = [] #Підготовлюємо місце для оброблених даних\n",
    "\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True): #Проганяючи кортежі через nlp, ми створюємо впорядковані доки, на які можно навішувати ярлики https://spacy.io/usage/processing-pipelines\n",
    "        doc.cats['World'] = 0 #Вішаємо ярлики\n",
    "        doc.cats['Sports'] = 0\n",
    "        doc.cats['Business'] = 0\n",
    "        doc.cats['Sci/Tech'] = 0\n",
    "        \n",
    "        if label==\"0\": #Призначаємо конкретний ярлик\n",
    "            doc.cats['World'] = 1\n",
    "        elif label==\"1\":\n",
    "            doc.cats['Sports'] = 1\n",
    "        elif label==\"2\":\n",
    "            doc.cats['Business']  = 1\n",
    "        elif label==\"3\":\n",
    "            doc.cats['Sci/Tech'] = 1\n",
    "        else:\n",
    "            print(\"Labeling error\")\n",
    "        \n",
    "        docs.append(doc) #Додаємо до масиву оброблених даних \n",
    "        \n",
    "    return df, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Auto-filled config with all values\n",
      "✔ Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config.cfg ./config.cfg #Підготовлюємо конфігураційний файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_process(trainDF) #Перетворюємо дані у читабельний формат\n",
    "first_process(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_docs = preprocess(trainDF, \"en_core_web_sm\") #Препроцесимо дані, використовуючи стандартний pipeline https://spacy.io/usage/models\n",
    "doc_bin = DocBin(docs=train_docs) #Серіалізуємо отримані дані\n",
    "doc_bin.to_disk(\"./textcat_train.spacy\") #Зберігаємо їх\n",
    "\n",
    "test_data, test_docs = preprocess(testDF, \"en_core_web_sm\") #Аналогічно\n",
    "doc_bin = DocBin(docs=test_docs)\n",
    "doc_bin.to_disk(\"./textcat_test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Saving to output directory: textcat_output\n",
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "✔ Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "ℹ Pipeline: ['tok2vec', 'textcat']\n",
      "ℹ Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ------------  ----------  ------\n",
      "  0       0          0.00          0.19        0.00    0.00\n",
      "  0     200         18.32         43.28       13.02    0.13\n",
      "  0     400         31.21         40.44        6.86    0.07\n",
      "  0     600         91.07         37.18       27.95    0.28\n",
      "  0     800         92.11         36.65       21.90    0.22\n",
      "  0    1000        106.62         35.65       30.41    0.30\n",
      "  0    1200        110.54         35.30       27.31    0.27\n",
      "  0    1400        307.91         32.97       37.01    0.37\n",
      "  0    1600        680.11         30.64       39.03    0.39\n",
      "  0    1800       1242.13         30.54       48.02    0.48\n",
      "  0    2000       4292.16         28.39       53.82    0.54\n",
      "  1    2200       8205.78         25.05       55.67    0.56\n",
      "  1    2400      11152.58         23.91       58.88    0.59\n",
      "  1    2600      19127.65         23.27       62.05    0.62\n",
      "  1    2800      30728.49         22.55       61.43    0.61\n",
      "  2    3000      33512.36         22.17       65.79    0.66\n",
      "  2    3200      42699.74         22.03       67.19    0.67\n",
      "  2    3400      59277.27         21.25       66.27    0.66\n",
      "  2    3600      74565.14         21.76       63.47    0.63\n",
      "  3    3800      86606.77         22.76       64.77    0.65\n",
      "  3    4000     108286.78         22.28       67.41    0.67\n",
      "  3    4200     134526.47         21.31       66.98    0.67\n",
      "  3    4400     167143.91         21.77       66.54    0.67\n",
      "  4    4600     161786.00         20.39       65.87    0.66\n",
      "  4    4800     239958.17         21.54       68.72    0.69\n",
      "  4    5000     295558.09         21.20       67.53    0.68\n",
      "  4    5200     298042.63         21.35       66.19    0.66\n",
      "  5    5400     308167.02         21.07       71.06    0.71\n",
      "  5    5600     360895.58         21.15       69.20    0.69\n",
      "  5    5800     391194.20         21.40       68.00    0.68\n",
      "  6    6000     393513.98         20.84       69.85    0.70\n",
      "  6    6200     474678.63         19.41       71.14    0.71\n",
      "  6    6400     646969.29         21.04       63.51    0.64\n",
      "  6    6600     625674.19         20.88       68.42    0.68\n",
      "  7    6800     759624.40         19.81       70.08    0.70\n",
      "  7    7000     776612.69         20.93       67.33    0.67\n",
      "  7    7200     957713.03         20.85       68.71    0.69\n",
      "  7    7400     938567.21         21.11       71.21    0.71\n",
      "  8    7600    1110029.47         20.87       70.22    0.70\n",
      "  8    7800    1235802.71         20.07       71.81    0.72\n",
      "  8    8000    1357141.65         20.35       71.21    0.71\n",
      "  8    8200    1245421.49         20.66       62.48    0.62\n",
      "  9    8400    1942493.49         20.80       72.17    0.72\n",
      "  9    8600    2019690.56         20.53       61.25    0.61\n",
      "  9    8800    1861026.42         21.04       65.75    0.66\n",
      " 10    9000    1857070.89         21.12       68.77    0.69\n",
      " 10    9200    2159385.48         20.62       66.62    0.67\n",
      " 10    9400    2294846.52         20.12       71.61    0.72\n",
      " 10    9600    2339453.03         19.94       67.05    0.67\n",
      " 11    9800    2873707.06         20.60       63.78    0.64\n",
      " 11   10000    2765052.42         20.56       71.13    0.71\n",
      "✔ Saved pipeline to output directory\n",
      "textcat_output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-09 20:09:47,388] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "[2022-12-09 20:09:47,747] [INFO] Set up nlp object from config\n",
      "[2022-12-09 20:09:47,768] [DEBUG] Loading corpus from path: textcat_test.spacy\n",
      "[2022-12-09 20:09:47,770] [DEBUG] Loading corpus from path: textcat_train.spacy\n",
      "[2022-12-09 20:09:47,770] [INFO] Pipeline: ['tok2vec', 'textcat']\n",
      "[2022-12-09 20:09:47,777] [INFO] Created vocabulary\n",
      "[2022-12-09 20:09:48,640] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "[2022-12-09 20:09:48,643] [INFO] Added vectors: en_core_web_sm\n",
      "[2022-12-09 20:09:48,646] [INFO] Finished initializing nlp object\n",
      "[2022-12-09 20:10:17,514] [INFO] Initialized pipeline components: ['tok2vec', 'textcat']\n",
      "[2022-12-09 20:10:17,534] [DEBUG] Loading corpus from path: textcat_test.spacy\n",
      "[2022-12-09 20:10:17,537] [DEBUG] Loading corpus from path: textcat_train.spacy\n",
      "[2022-12-09 20:10:17,539] [DEBUG] Removed existing output directory: textcat_output\\model-best\n",
      "[2022-12-09 20:10:17,541] [DEBUG] Removed existing output directory: textcat_output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ./config.cfg --verbose --output ./textcat_output --paths.train ./textcat_train.spacy --paths.dev ./textcat_test.spacy #Стартуємо навчання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_process(validDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Підготовуємо валідаційні дані\n",
    "valid_data, valid_docs = preprocess(validDF, \"en_core_web_sm\") \n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"./textcat_valid.spacy\")\n",
    "\n",
    "#Застосовуємо модель до валідаційних даних\n",
    "nlp_model = spacy.load(\"./textcat_output/model-best\")\n",
    "valid_text = valid_data.description.tolist()\n",
    "valid_cats = valid_data.label.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Nicolas Massu beat Taylor Dent of the United States 7-6 (5), 6-1 Friday in the tennis semifinals to move within one victory of giving Chile its first Olympic gold medal in any sport. \n",
      "Original category: 1\n",
      "Predicted:\n",
      "{'World': 0.0036531013902276754, 'Sports': 0.9944242835044861, 'Business': 0.0007581915124319494, 'Sci/Tech': 0.0011644094483926892}\n"
     ]
    }
   ],
   "source": [
    "#Виведемо випадкове передбачення\n",
    "import random\n",
    "i=random.randrange(0,100)\n",
    "doc_valid = nlp_model(valid_text[i])\n",
    "print(\"Text: \" + valid_text[i] + \"\\nOriginal category: \" + valid_cats[i] + \"\\nPrediction: \" + doc_valid.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   71.75 \n",
      "SPEED               2938  \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "               P       R       F\n",
      "World      73.66   64.96   69.04\n",
      "Sports     94.42   78.15   85.52\n",
      "Business   70.16   53.60   60.77\n",
      "Sci/Tech   83.02   63.08   71.69\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "           ROC AUC\n",
      "World         0.90\n",
      "Sports        0.98\n",
      "Business      0.86\n",
      "Sci/Tech      0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate textcat_output/model-best textcat_valid.spacy #Застосовуємо модель до валідаційних даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   72.17 \n",
      "SPEED               2956  \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "               P       R       F\n",
      "World      71.53   68.39   69.93\n",
      "Sports     93.99   77.91   85.20\n",
      "Business   72.18   58.05   64.35\n",
      "Sci/Tech   77.52   62.53   69.22\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "           ROC AUC\n",
      "World         0.88\n",
      "Sports        0.96\n",
      "Business      0.87\n",
      "Sci/Tech      0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate textcat_output/model-best textcat_test.spacy #Застосовуємо модель до тестових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   74.97 \n",
      "SPEED               3090  \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "               P       R       F\n",
      "World      73.18   70.54   71.84\n",
      "Sports     96.11   83.58   89.41\n",
      "Business   73.72   57.86   64.83\n",
      "Sci/Tech   83.76   65.95   73.80\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "           ROC AUC\n",
      "World         0.90\n",
      "Sports        0.98\n",
      "Business      0.88\n",
      "Sci/Tech      0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate textcat_output/model-best textcat_train.spacy #Застосовуємо модель до тренувальних даних"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('Learning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1212554032050257e17db41b12d1bf2a52a9d05eca02e4403131d81d47f6ec88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
